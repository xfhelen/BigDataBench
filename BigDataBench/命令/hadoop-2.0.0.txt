每次重启要先: cd $HADOOP_HOME/bin; ./hadoop namenode -format
update-alternatives --config java
export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH

sudo apt-get install openjdk-6-jre
apt-get install build-essential
apt-get install vim
apt-get update

sudo apt-get install ssh
ssh-keygen -t rsa -P ""
cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
ssh localhost

wget http://archive.cloudera.com/cdh4/cdh/4/hadoop-2.0.0-cdh4.2.0.tar.gz
tar -xzvf hadoop-2.0.0-cdh4.2.0.tar.gz

vim ~/.bash_profile
export HADOOP_HOME=/root/hadoop-2.0.0-cdh4.2.0
export YARN_HOME=/root/hadoop-2.0.0-cdh4.2.0
export HADOOP_HDFS_HOME=/root/hadoop-2.0.0-cdh4.2.0
export PATH=$HADOOP_HOME/bin:$PATH
source ~/.bash_profile

cd $HADOOP_HOME/etc/hadoop/

vim hadoop-env.sh
export JAVA_HOME=/usr/lib/jvm/java-6-openjdk-amd64

vim core-site.xml
<property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/home/hadoop_file/tmp</value>
</property>

vim hdfs-site.xml
<property>
<name>dfs.name.dir</name>
<value>/home/hadoop_file/name</value>
</property>
<property>
<name>dfs.data.dir</name>
<value>/home/hadoop_file/data</value>
</property>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>

vim yarn-site.xml
<property>
<name>yarn.resoucemanager.address</name>
<value>localhost:8032</value>
</property>
<property>
<name>yarn.resourcemanager.scheduler.address</name>
<value>localhost:8030</value>
</property>
<property>
<name>yarn.resourcemanager.resource-tracker.address</name>
<value>localhost:8031</value>
</property>
<property>
<name>yarn.resourcemanager.admin.address</name>
<value>localhost:8033</value>
</property>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce.shuffle</value>
</property>

wget http://archive.cloudera.com/cdh4/redhat/6/x86_64/cdh/4.2.0/RPMS/x86_64/hadoop-2.0.0+922-1.cdh4.2.0.p0.12.el6.x86_64.rpm
apt-get install rpm2cpio
rpm2cpio hadoop-2.0.0+922-1.cdh4.2.0.p0.12.el6.x86_64.rpm | cpio -div

cd /root/usr/lib/hadoop/lib/native/
rm libhadoop.so
rm libsnappy.so
rm libsnappy.so.1
ln -s libhadoop.so.1.0.0 libhadoop.so
ln -s libsnappy.so.1.1.3 libsnappy.so.1
ln -s libsnappy.so.1.1.3 libsnappy.so
cd ..
tar -zcf native.tar.gz native

cd $HADOOP_HOME/bin
./hadoop namenode -format
cd $HADOOP_HOME/sbin
./start-all.sh
./stop-all.sh




